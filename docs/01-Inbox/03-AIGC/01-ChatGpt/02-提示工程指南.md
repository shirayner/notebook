---
sidebar_label: 提示工程指南
tags:
  - ChatGpt
  - AIGC
---
# 提示工程指南

## 推荐阅读

> - [What is Prompt Engineering?](https://www.promptengineering.org/what-is-prompt-engineering/)

其他：

- [ChatGPT是什么?](https://www.w3cschool.cn/openai_doc/openai_doc-5r4o3rob.html)
- [ChatGPT 提示的艺术：制作清晰有效咒语](https://github.com/wikieden/Awesome-ChatGPT-Prompts-CN/blob/main/ChatGpt-receipt.md)
- [【ChatGPT】一文教你怎么编写清晰有效的（Prompt）提示词~](https://juejin.cn/post/7215536461478707258)
- [【2023】猫娘方法持续讨论更新](https://github.com/PlexPt/awesome-chatgpt-prompts-zh/issues/12)
- [解除封印咒语](https://github.com/PlexPt/awesome-chatgpt-prompts-zh/blob/main/cat.md)
- [写好ChatGPT提示词的10个技巧](https://www.niaogebiji.com/article-553890-1.html)
- [在 ChatGPT 中构建虚拟机](https://www.w3cschool.cn/openai_doc/openai_doc-gr643rkm.html)

## ChatGPT提示词参考

提示词开源项目：

| **项目**                                                                         | **描述**                                                           |
| -------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| [PlexPt/awesome-chatgpt-prompts-zh](https://github.com/PlexPt/awesome-chatgpt-prompts-zh) | 【提示词】ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。 |
| [f/awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts)                 | This repo includes ChatGPT prompt curation to use ChatGPT better.        |

提示词网站：

| **项目**                                                             | **描述**                                                                                                                                 |
| -------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| [wenhaomin/GPT-PromptGenius](https://github.com/wenhaomin/GPT-PromptGenius)   | 【提示词网站】全面、有效的提示词大全网站，帮助提升生产力和质量。                                                                               |
| [rockbenben/ChatGPT-Shortcut](https://github.com/rockbenben/ChatGPT-Shortcut) | Maximize your efficiency and productivity. 让生产力加倍的 ChatGPT 快捷指令，按照领域和功能分区，可对提示词进行标签筛选、关键词搜索和一键复制。 |
| [chatgpt-prompts](https://www.quanzhan.co/ai/chatgpt-prompts)                 | 提示词网站、AI工具箱导航                                                                                                                       |

## 提示词教程

> * [datawhalechina/prompt-engineering-for-developers](https://github.com/datawhalechina/prompt-engineering-for-developers)
> * [AIGC - ChatGPT从入门到应用](https://datawhaler.feishu.cn/docx/MNHBdr7hqoEdNexMoi2cbYpcnTe)
> * [dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)

## 一、提示工程简介

提示工程（Prompt Engineering）是人工智能 (AI) 中的一个概念，特别是自然语言处理，主要关注于提示词的设计、改进和优化，从而指导大语言模型更好的完成特定任务。

### 1.大语言模型设置

使用提示词时，您会通过 API 或直接与大语言模型进行交互。你可以通过配置一些参数以获得不同的提示结果。

 **Temperature** ：简单来说，`temperature` 的参数值越小，模型就会返回越确定的一个结果。如果调高该参数值，大语言模型可能会返回更随机的结果，也就是说这可能会带来更多样化或更具创造性的产出。我们目前也在增加其他可能 token 的权重。在实际应用方面，对于质量保障（QA）等任务，我们可以设置更低的 `temperature` 值，以促使模型基于事实返回更真实和简洁的结果。 对于诗歌生成或其他创造性任务，你可以适当调高 `temperature` 参数值。

 **Top_p** ：同样，使用 `top_p`（与 `temperature` 一起称为核采样的技术），可以用来控制模型返回结果的真实性。如果你需要准确和事实的答案，就把参数值调低。如果你想要更多样化的答案，就把参数值调高一些。

一般建议是改变其中一个参数就行，不用两个都调整。

在我们开始一些基础示例之前，请记住最终生成的结果可能会和使用的大语言模型的版本不同有关。

### 2.提示词格式

标准提示词应该遵循以下格式：

```
<问题>?
```

或

```
<指令>
```

这种可以被格式化为标准的问答格式，如：

```
Q: <问题>?A: 
```

以上的提示方式，也被称为**零样本提示（zero-shot prompting）**，即用户不提供任务结果相关的示范，直接提示语言模型给出任务相关的回答。某些大型语言模式有能力实现零样本提示，但这也取决于任务的复杂度和已有的知识范围。

基于以上标准范式，目前业界普遍使用的还是更高效的_小样本提示（Few-shot Prompting）_范式，即用户提供少量的提示范例，如任务说明等。小样本提示一般遵循以下格式：

```
<问题>?
<答案>
<问题>?
<答案>
<问题>?
<答案>
<问题>?
```

而问答模式即如下：

```
Q: <问题>?
A: <答案>
Q: <问题>?
A: <答案>
Q: <问题>?
A: <答案>
Q: <问题>?
A:
```

注意，使用问答模式并不是必须的。你可以根据任务需求调整提示范式。比如，您可以按以下示例执行一个简单的分类任务，并对任务做简单说明：

*提示词*

```
This is awesome! // Positive
This is bad! // Negative
Wow that movie was rad! // Positive
What a horrible show! //
```

*输出结果*

```
Negative
```

语言模型可以基于一些说明了解和学习某些任务，而小样本提示正好可以赋能上下文学习能力。

### 3.提示词要素

提示词可以包含以下任意要素：

- **指令** ：想要模型执行的特定任务或指令。
- **上下文** ：包含外部信息或额外的上下文信息，引导语言模型更好地响应。
- **输入数据** ：用户输入的内容或问题。
- **输出指示** ：指定输出的类型或格式。

注意，提示词所需的格式取决于您想要语言模型完成的任务类型，并非所有以上要素都是必须的。

## 二、提示词常用场景

主题：

* [文本概括](https://www.promptingguide.ai/zh/introduction/examples#%E6%96%87%E6%9C%AC%E6%A6%82%E6%8B%AC)
* [信息提取](https://www.promptingguide.ai/zh/introduction/examples#%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96)
* [问答](https://www.promptingguide.ai/zh/introduction/examples#%E9%97%AE%E7%AD%94)
* [文本分类](https://www.promptingguide.ai/zh/introduction/examples#%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB)
* [对话](https://www.promptingguide.ai/zh/introduction/examples#%E5%AF%B9%E8%AF%9D)
* [代码生成](https://www.promptingguide.ai/zh/introduction/examples#%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90)
* [推理](https://www.promptingguide.ai/zh/introduction/examples#%E6%8E%A8%E7%90%86)

### 1.文本概括

技巧：

> - 限制输出文本长度
> - 侧重点
> - 信息提取

（1）限制输出文本长度

提示词：

```

你的任务是从电子商务网站上生成一个产品评论的简短摘要。

请对三个双引号之间的评论文本进行概括，最多30个词汇。

评论:
"""
这个熊猫公仔是我给女儿的生日礼物，她很喜欢，去哪都带着。
公仔很软，超级可爱，面部表情也很和善。但是相比于价钱来说，
它有点小，我感觉在别的地方用同样的价钱能买到更大的。
快递比预期提前了一天到货，所以在送给女儿之前，我自己玩了会。  
"""
```

输出结果：

```
超级可爱的熊猫公仔，女儿非常喜欢，但有点小，相对价钱来说更大的可以买到。快递提前一天到达。
```

（2）侧重点

有时，针对不同的业务，我们对文本的侧重会有所不同。例如对于商品评论文本，物流会更关心运输时效，商家更加关心价格与商品质量，平台更关心整体服务体验。

我们可以通过增加Prompt提示，来体现对于某个特定角度的侧重。

提示词：

```

你的任务是从电子商务网站上生成一个产品评论的简短摘要。

请对三个双引号之间的评论文本进行概括，最多30个词汇，并且聚焦在产品运输上。

评论:
"""
这个熊猫公仔是我给女儿的生日礼物，她很喜欢，去哪都带着。
公仔很软，超级可爱，面部表情也很和善。但是相比于价钱来说，
它有点小，我感觉在别的地方用同样的价钱能买到更大的。
快递比预期提前了一天到货，所以在送给女儿之前，我自己玩了会。  
"""

```

输出结果：

```
提前一天到达的超级可爱熊猫公仔，女儿喜欢，但有点小。比较价钱，在别的地方能买到更大的。
```

（3）信息提取

提示词：

```

你的任务是从电子商务网站上的产品评论中提取相关信息。

请从以下三个双引号之间的评论文本中提取产品运输相关的信息，最多30个词汇。

评论:
"""
这个熊猫公仔是我给女儿的生日礼物，她很喜欢，去哪都带着。
公仔很软，超级可爱，面部表情也很和善。但是相比于价钱来说，
它有点小，我感觉在别的地方用同样的价钱能买到更大的。
快递比预期提前了一天到货，所以在送给女儿之前，我自己玩了会。  
"""

```

输出结果：

```
快递提前一天到货。
```

### 2.推断

技巧：

> * 推断情感、情感类型
> * 推断主题
> * 提取标签、实体

推断情感、主题，提取标签、实体等

#### 2.1 推断情感

（1）推断情感（正向/负向）

提示词：

```
以下用三个双引号分隔的产品评论的情感是什么？
用一个单词回答：「正面」、「负面」、[中性]。
评论:
"""
我需要一盏漂亮的卧室灯，这款灯具有额外的储物功能，价格也不算太高。\
我很快就收到了它。在运输过程中，我们的灯绳断了，但是公司很乐意寄送了一个新的。\
几天后就收到了。这款灯很容易组装。我发现少了一个零件，于是联系了他们的客服，他们很快就给我寄来了缺失的零件！\
在我看来，Lumina 是一家非常关心顾客和产品的优秀公司！
"""
```

输出结果：

```
评论的情感是积极的。
```

(2) 识别情感类型

提示词：

```
识别以下评论的作者表达的情感。包含不超过五个项目。将答案格式化为以逗号分隔的单词列表。
评论:
"""
我需要一盏漂亮的卧室灯，这款灯具有额外的储物功能，价格也不算太高。\
我很快就收到了它。在运输过程中，我们的灯绳断了，但是公司很乐意寄送了一个新的。\
几天后就收到了。这款灯很容易组装。我发现少了一个零件，于是联系了他们的客服，他们很快就给我寄来了缺失的零件！\
在我看来，Lumina 是一家非常关心顾客和产品的优秀公司！
"""
```

输出结果：

```
满意,感激,乐观,赞赏,肯定
```

（3）识别愤怒

提示词：

```
以下评论的作者是否表达了愤怒？评论用三个双引号分隔。
请回答：「是」、「否]。
评论:
"""
我需要一盏漂亮的卧室灯，这款灯具有额外的储物功能，价格也不算太高。\
我很快就收到了它。在运输过程中，我们的灯绳断了，但是公司很乐意寄送了一个新的。\
几天后就收到了。这款灯很容易组装。我发现少了一个零件，于是联系了他们的客服，他们很快就给我寄来了缺失的零件！\
在我看来，Lumina 是一家非常关心顾客和产品的优秀公司！
"""
```

输出结果：

```
评论的情感是积极的。
```

#### 2.2 提取实体

提取产品名称和公司名称

提示词：

```
从评论文本中识别以下项目：
- 评论者购买的物品
- 制造该物品的公司

评论文本用三个反引号分隔。将你的响应格式化为以 “物品” 和 “品牌” 为键的 JSON 对象。
如果信息不存在，请使用 “未知” 作为值。
让你的回应尽可能简短。

评论:
"""
我需要一盏漂亮的卧室灯，这款灯具有额外的储物功能，价格也不算太高。\
我很快就收到了它。在运输过程中，我们的灯绳断了，但是公司很乐意寄送了一个新的。\
几天后就收到了。这款灯很容易组装。我发现少了一个零件，于是联系了他们的客服，他们很快就给我寄来了缺失的零件！\
在我看来，Lumina 是一家非常关心顾客和产品的优秀公司！
"""
```

输出结果

```
{
  "物品": "卧室灯",
  "品牌": "Lumina"
}
```

一次完成多个任务

提示词：

```
从评论文本中识别以下项目：
- 情绪（正面或负面）
- 审稿人是否表达了愤怒？（是或否）
- 评论者购买的物品
- 制造该物品的公司

评论用三个反引号分隔。将您的响应格式化为 JSON 对象，以 “Sentiment”、“Anger”、“Item” 和 “Brand” 作为键。
如果信息不存在，请使用 “未知” 作为值。
让你的回应尽可能简短。
将 Anger 值格式化为布尔值。

评论:
"""
我需要一盏漂亮的卧室灯，这款灯具有额外的储物功能，价格也不算太高。\
我很快就收到了它。在运输过程中，我们的灯绳断了，但是公司很乐意寄送了一个新的。\
几天后就收到了。这款灯很容易组装。我发现少了一个零件，于是联系了他们的客服，他们很快就给我寄来了缺失的零件！\
在我看来，Lumina 是一家非常关心顾客和产品的优秀公司！
"""
```

输出结果

```
{
"Sentiment": "正面",
"Anger": false,
"Item": "卧室灯",
"Brand": "Lumina"
}
```

#### 2.3 推断主题

提示词：

```
确定以下用三个双引号分割的给定文本中讨论的五个主题。

每个主题用1-2个单词概括。

输出时用逗号分割每个主题。

给定文本:
"""
在政府最近进行的一项调查中，要求公共部门的员工对他们所在部门的满意度进行评分。
调查结果显示，NASA 是最受欢迎的部门，满意度为 95％。

一位 NASA 员工 John Smith 对这一发现发表了评论，他表示：
“我对 NASA 排名第一并不感到惊讶。这是一个与了不起的人们和令人难以置信的机会共事的好地方。我为成为这样一个创新组织的一员感到自豪。”

NASA 的管理团队也对这一结果表示欢迎，主管 Tom Johnson 表示：
“我们很高兴听到我们的员工对 NASA 的工作感到满意。
我们拥有一支才华横溢、忠诚敬业的团队，他们为实现我们的目标不懈努力，看到他们的辛勤工作得到回报是太棒了。”

调查还显示，社会保障管理局的满意度最低，只有 45％的员工表示他们对工作满意。
政府承诺解决调查中员工提出的问题，并努力提高所有部门的工作满意度。
"""
```

输出结果

```
调查, 满意度, NASA, 社会保障管理局, 政府承诺
```

查找是否包含特定主题

提示词：

```
判断主题列表中的每一项是否是给定文本中的一个话题，

以列表的形式给出答案，每个主题用 0 或 1。

主题列表：美国航空航天局、当地政府、工程、员工满意度、联邦政府

给定文本:
"""
在政府最近进行的一项调查中，要求公共部门的员工对他们所在部门的满意度进行评分。
调查结果显示，NASA 是最受欢迎的部门，满意度为 95％。

一位 NASA 员工 John Smith 对这一发现发表了评论，他表示：
“我对 NASA 排名第一并不感到惊讶。这是一个与了不起的人们和令人难以置信的机会共事的好地方。我为成为这样一个创新组织的一员感到自豪。”

NASA 的管理团队也对这一结果表示欢迎，主管 Tom Johnson 表示：
“我们很高兴听到我们的员工对 NASA 的工作感到满意。
我们拥有一支才华横溢、忠诚敬业的团队，他们为实现我们的目标不懈努力，看到他们的辛勤工作得到回报是太棒了。”

调查还显示，社会保障管理局的满意度最低，只有 45％的员工表示他们对工作满意。
政府承诺解决调查中员工提出的问题，并努力提高所有部门的工作满意度。
"""
```

输出结果

```
调查, 满意度, NASA, 社会保障管理局, 政府承诺
```

### 3.文本转换

#### 3.1 语种识别

提示词：

```
请告诉我以下文本是什么语种: 
"""
Combien coûte le lampadaire?
"""
```

输出结果

```
该文本是法语。
```

#### 3.2 文本翻译

（1）单语种翻译

提示词：

```
将以下中文翻译成西班牙语: \ 
"""
您好，我想订购一个搅拌机。 
"""
```

输出结果

```
Hola, me gustaría ordenar una batidora.
```

(2) 多语种翻译

提示词：

```
请将以下文本分别翻译成中文、英文、法语和西班牙语: 
"""
I want to order a basketball.
"""
```

输出结果

```
中文：我想订购一个篮球。
英文：I want to order a basketball.
法语：Je veux commander un ballon de basket.
西班牙语：Quiero ordenar una pelota de baloncesto.
```

(3) 翻译+正式语气

提示词：

```
请将以下文本翻译成中文，分别展示成正式与非正式两种语气: 
"""
Would you like to order a pillow?
"""

```

输出结果：

```
正式语气：请问您需要订购枕头吗？
非正式语气：你要不要订一个枕头？
```

#### 3.3 语气/风格调整

写作的语气往往会根据受众对象而有所调整。例如，对于工作邮件，我们常常需要使用正式语气与书面用词，而对同龄朋友的微信聊天，可能更多地会使用轻松、口语化的语气。

提示词：

```
将以下文本翻译成商务信函的格式: 
"""
小老弟，我小羊，上回你说咱部门要采购的显示器是多少寸来着？
"""
```

输出结果：

```
尊敬的先生/女士，

我是小羊，我们上次讨论中提到我们部门需要采购显示器，请问您还记得需要多大尺寸的显示器吗？

谢谢您的关注与合作。

祝好，
小羊
```

#### 3.4 格式转换

ChatGPT非常擅长不同格式之间的转换，例如JSON到HTML、XML、Markdown等。在下述例子中，我们有一个包含餐厅员工姓名和电子邮件的列表的JSON，我们希望将其从JSON转换为HTML。

提示词：

```
将以下Python字典从JSON转换为MarkDown表格，保留表格标题和列名：
"""
 { "resturant employees" :[ 
    {"name":"Shyam", "email":"shyamjaiswal@gmail.com"},
    {"name":"Bob", "email":"bob32@gmail.com"},
    {"name":"Jai", "email":"jai87@gmail.com"}
]}
"""
```

输出结果：

```
| resturant employees | name  | email                 |
|---------------------|-------|-----------------------|
|                     | Shyam | shyamjaiswal@gmail.com |
|                     | Bob   | bob32@gmail.com       |
|                     | Jai   | jai87@gmail.com       |

```

#### 3.5 拼写及语法纠正

拼写及语法的检查与纠正是一个十分常见的需求，特别是使用非母语语言，例如发表英文论文时，这是一件十分重要的事情。

以下给了一个例子，有一个句子列表，其中有些句子存在拼写或语法问题，有些则没有，我们循环遍历每个句子，要求模型校对文本，如果正确则输出“未发现错误”，如果错误则输出纠正后的文本。

提示词：

```
请校对并更正以下文本，注意纠正文本保持原始语种，无需输出原始文本。
    如果您没有发现任何错误，请说“未发现错误”。
  
    例如：
    输入：I are happy.
    输出：I am happy.
"""
The girl with the black and white puppies have a ball.
Yolanda has her notebook.
Their goes my freedom. There going to bring they’re suitcases.
"""
```

输出结果：

```
The girl with the black and white puppies has a ball.
Yolanda has her notebook.
There goes my freedom. They're going to bring their suitcases.
```

### 4.文本扩展

我们可以将短文本输入到大型语言模型中，让模型生成更长的文本，例如基于某个主题的电子邮件或论文。

提示词：

```
你是一位客户服务的AI助手。
你的任务是给一位重要客户发送邮件回复。
根据客户通过三个双引号分隔的评价，生成回复以感谢客户的评价。提醒模型使用评价中的具体细节
用简明而专业的语气写信。
作为“AI客户代理”签署电子邮件。
客户评论：
"""
他们在11月份的季节性销售期间以约49美元的价格出售17件套装，折扣约为一半。\
但由于某些原因（可能是价格欺诈），到了12月第二周，同样的套装价格全都涨到了70美元到89美元不等。\
11件套装的价格也上涨了大约10美元左右。\
虽然外观看起来还可以，但基座上锁定刀片的部分看起来不如几年前的早期版本那么好。\
不过我打算非常温柔地使用它，例如，\
我会先在搅拌机中将像豆子、冰、米饭等硬物研磨，然后再制成所需的份量，\
切换到打蛋器制作更细的面粉，或者在制作冰沙时先使用交叉切割刀片，然后使用平面刀片制作更细/不粘的效果。\
制作冰沙时，特别提示：\
将水果和蔬菜切碎并冷冻（如果使用菠菜，则轻轻煮软菠菜，然后冷冻直到使用；\
如果制作果酱，则使用小到中号的食品处理器），这样可以避免在制作冰沙时添加太多冰块。\
大约一年后，电机发出奇怪的噪音，我打电话给客服，但保修已经过期了，所以我不得不再买一个。\
总的来说，这些产品的总体质量已经下降，因此它们依靠品牌认可和消费者忠诚度来维持销售。\
货物在两天内到达。
"""
评论情感：negative
```

输出结果：

```
尊敬的客户，

非常感谢您给我们提供的评价和反馈。我们非常重视您的意见，以及您对我们产品和服务的体验。

首先，我们对价格上涨的情况表示歉意。我们会进一步审查和调整我们的定价策略，以确保价格的合理性和稳定性。

关于产品质量方面的问题，我们深感遗憾。我们一直致力于提供优质可靠的产品，您的反馈对于我们改进产品的设计和制造过程非常重要。我们会将您提到的问题传达给我们的研发团队，并努力改进基座锁定刀片的部分。

同时，您对使用搅拌机的详细方式和技巧的分享非常有帮助。我们会将这些建议传达给我们的用户指南和说明书，以帮助其他客户更好地使用我们的产品。

对于售后服务方面的问题，我们深感抱歉。我们将进一步改进我们的客户支持体系，确保及时响应客户的需求和问题，并提供更长的保修期限。

您的反馈对我们非常重要，我们将一如既往地努力提供卓越的产品和服务。如果您有任何其他问题或需求，请随时联系我们的客户支持团队。

再次感谢您对我们的支持和反馈。

祝好！

AI客户代理
```

### 5.问答与对话

提示词：

```
根据以下上下文回答问题。 保持答案简短明了。 如果不确定答案，请回复“Unsure about answer”。 // 基于以下环境回答问题。如果不知道回答的话题，请回答“不确定回答”。
背景：Teplizumab 的根源可以追溯到一家名为 Ortho Pharmaceutical 的新泽西制药公司。 在那里，科学家们生成了早期版本的抗体，称为 OKT3。 该分子最初来自小鼠，能够与 T 细胞表面结合并限制其杀伤细胞的潜力。 1986 年，它被批准用于帮助预防肾脏移植后的器官排斥反应，使其成为第一个被允许用于人类的治疗性抗体。
问：OKT3最初来源于什么？
```

输出结果：

```
OKT3最初来源于小鼠。
```

对话系统：

提示词：

```
以下是与一位AI研究助理的对话。 助理语气是技术性的、科学性的。 // 以下是与 AI 助理的对话，语气应该专业、技术性强。
人类：你好，你是谁？
AI：您好！ 我是一名人工智能研究助理。 今天我能帮到你什么？
人类：你能告诉我黑洞的产生吗？
AI：
```

输出结果：

```
当恒星耗尽其核心燃料并发生引力坍缩时，会形成一种非常致密的天体，称为黑洞。黑洞的产生通常与超新星爆发或超大质量恒星坍塌有关。在恒星坍缩的过程中，引力会将其物质压缩到极高的密度，形成一个无法逃逸的引力场，即事件视界。事件视界内的物质和能量被吸引到其中心，形成了所谓的黑洞。黑洞的引力极强，连光也无法逃脱其吸引力范围，因此得名"黑洞"。

黑洞是宇宙中最极端的天体之一，其密度和引力场对周围空间产生深远影响。它们在宇宙中起着重要的作用，并且对我们理解宇宙演化和引力物理学提供了重要线索。
```

提示词：

```
以下是与一位AI研究助理的对话。 辅助答案应该是连小学生都能看懂的。
人类：你好，你是谁？
艾：您好！ 我是一名人工智能研究助理。 今天我能帮到你什么？
人类：你能告诉我黑洞的产生吗？
人工智能：
```

输出结果：

```
当某个星体的内部燃料耗尽时，它可能会发生坍缩，形成一个非常小而非常重的物体，称为黑洞。这种坍缩会使星体的物质密度变得极高，就像把一个大东西压缩到一个很小的空间里一样。黑洞的引力非常强大，甚至连光也无法逃离它的吸引。所以我们称之为"黑洞"，因为它不会反射或发射任何光线。

黑洞对周围的物质和空间产生很大的影响。它们可以吸引附近的物质，有时候甚至会吞噬其他星体。黑洞的存在对于我们理解宇宙中的引力和宇宙演化非常重要。

虽然黑洞是非常奇特和神秘的天体，但科学家们一直在努力研究它们，以便更好地了解宇宙的运作方式。
```

### 6.代码生成

提示词：

```
"""
Table departments, columns = [DepartmentId, DepartmentName]
Table students, columns = [DepartmentId, StudentId, StudentName]
Create a MySQL query for all students in the Computer Science Department
"""
```

输出结果：

```
SELECT students.StudentName
FROM students
INNER JOIN departments ON students.DepartmentId = departments.DepartmentId
WHERE departments.DepartmentName = 'Computer Science';
```

## 三、提示词技术

### 1.零样本提示

如今，经过大量数据训练并调整指令的LLM能够执行零样本任务。我们在前一节中尝试了一些零样本示例。以下是我们使用的一个示例：

*提示：*

```
将文本分类为中性、负面或正面。
文本：我认为这次假期还可以。
情感：
```

*输出：*

```
中性
```

请注意，在上面的提示中，我们没有向模型提供任何示例——这就是零样本能力的作用。

指令调整已被证明可以改善零样本学习[Wei等人（2022）(opens in a new tab)](https://arxiv.org/pdf/2109.01652.pdf)。指令调整本质上是在通过指令描述的数据集上微调模型的概念。此外，[RLHF(opens in a new tab)](https://arxiv.org/abs/1706.03741)（来自人类反馈的强化学习）已被采用以扩展指令调整，其中模型被调整以更好地适应人类偏好。这一最新发展推动了像ChatGPT这样的模型。我们将在接下来的章节中讨论所有这些方法和方法。

当零样本不起作用时，建议在提示中提供演示或示例，这就引出了少样本提示。

### 2.少样本提示

#### 少样本提示的示例

虽然大型语言模型展示了惊人的零样本能力，但在使用**零样本**设置时，它们**在更复杂的任务上仍然表现不佳**。少样本提示可以作为一种技术，以启用**上下文学习**，我们在提示中提供演示以引导模型实现更好的性能。演示作为后续示例的条件，我们希望模型生成响应。

让我们通过[Brown等人2020年(opens in a new tab)](https://arxiv.org/abs/2005.14165)提出的一个例子来演示少样本提示。在这个例子中，任务是在句子中正确使用一个新词。

*提示：*

```
“whatpu”是坦桑尼亚的一种小型毛茸茸的动物。一个使用whatpu这个词的句子的例子是：
我们在非洲旅行时看到了这些非常可爱的whatpus。
“farduddle”是指快速跳上跳下。一个使用farduddle这个词的句子的例子是：
```

*输出：*

```
当我们赢得比赛时，我们都开始庆祝跳跃。
```

我们可以观察到，模型通过提供一个示例（即1-shot）已经学会了如何执行任务。对于更困难的任务，我们可以尝试增加演示（例如3-shot、5-shot、10-shot等）。

根据[Min等人（2022）(opens in a new tab)](https://arxiv.org/abs/2202.12837)的研究结果，以下是在进行少样本学习时关于演示/范例的一些额外提示：

* “标签空间和演示指定的输入文本的分布都很重要（无论标签是否对单个输入正确）”
* 使用的格式也对性能起着关键作用，即使只是使用随机标签，这也比没有标签好得多。
* 其他结果表明，从真实标签分布（而不是均匀分布）中选择随机标签也有帮助。

让我们尝试一些例子。让我们首先尝试一个随机标签的例子（意味着将标签Negative和Positive随机分配给输入）：

*提示：*

```
这太棒了！// Negative这太糟糕了！// Positive哇，那部电影太棒了！// Positive多么可怕的节目！//
```

*输出：*

```
Negative
```

即使标签已经随机化，我们仍然得到了正确的答案。请注意，我们还保留了格式，这也有助于。实际上，通过进一步的实验，我们发现我们正在尝试的新GPT模型甚至对随机格式也变得更加稳健。例如：

*提示：*

```
Positive This is awesome! This is bad! NegativeWow that movie was rad!PositiveWhat a horrible show! --
```

*输出：*

```
Negative
```

上面的格式不一致，但模型仍然预测了正确的标签。我们必须进行更彻底的分析，以确认这是否适用于不同和更复杂的任务，包括提示的不同变体。

#### 少样本提示的限制

标准的少样本提示对许多任务都有效，但仍然不是一种完美的技术，特别是在处理更复杂的推理任务时。让我们演示为什么会这样。您是否还记得之前提供的任务：

```
这组数字中的奇数加起来是一个偶数：15、32、5、13、82、7、1。A：
```

如果我们再试一次，模型输出如下：

```
是的，这组数字中的奇数加起来是107，是一个偶数。
```

这不是正确的答案，这不仅突显了这些系统的局限性，而且需要更高级的提示工程。

让我们尝试添加一些示例，看看少样本提示是否可以改善结果。

*提示：*

```
这组数字中的奇数加起来是一个偶数：4、8、9、15、12、2、1。
A：答案是False。
这组数字中的奇数加起来是一个偶数：17、10、19、4、8、12、24。
A：答案是True。
这组数字中的奇数加起来是一个偶数：16、11、14、4、8、13、24。
A：答案是True。
这组数字中的奇数加起来是一个偶数：17、9、10、12、13、4、2。
A：答案是False。
这组数字中的奇数加起来是一个偶数：15、32、5、13、82、7、1。
A：
```

*输出：*

```
答案是True。
```

这没用。似乎少样本提示不足以获得这种类型的推理问题的可靠响应。上面的示例提供了任务的基本信息。如果您仔细观察，我们引入的任务类型涉及几个更多的推理步骤。换句话说，如果我们将问题分解成步骤并向模型演示，这可能会有所帮助。最近，[思维链（CoT）提示(opens in a new tab)](https://arxiv.org/abs/2201.11903) 已经流行起来，以解决更复杂的算术、常识和符号推理任务。

总的来说，提供示例对解决某些任务很有用。当零样本提示和少样本提示不足时，这可能意味着模型学到的东西不足以在任务上表现良好。从这里开始，建议开始考虑微调您的模型或尝试更高级的提示技术。接下来，我们将讨论一种流行的提示技术，称为思维链提示，它已经获得了很多关注。

### 3.思维链提示

#### 链式思考（CoT）提示

![COT](https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcot.1933d9fe.png&w=1920&q=75)

图片来源：[Wei等人（2022）(opens in a new tab)](https://arxiv.org/abs/2201.11903)

在[Wei等人（2022）(opens in a new tab)](https://arxiv.org/abs/2201.11903)中引入的链式思考（CoT）提示通过中间推理步骤实现了复杂的推理能力。您可以将其与少样本提示相结合，以获得更好的结果，以便在回答之前进行推理的更复杂的任务。

*提示：*

```
这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。
A：将所有奇数相加（9、15、1）得到25。答案为False。
这组数中的奇数加起来是偶数：17、10、19、4、8、12、24。
A：将所有奇数相加（17、19）得到36。答案为True。
这组数中的奇数加起来是偶数：16、11、14、4、8、13、24。
A：将所有奇数相加（11、13）得到24。答案为True。
这组数中的奇数加起来是偶数：17、9、10、12、13、4、2。
A：将所有奇数相加（17、9、13）得到39。答案为False。
这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。
A：
```

*输出：*

```
将所有奇数相加（15、5、13、7、1）得到41。答案为False。
```

哇！我们可以看到在提供推理步骤时得到了完美的结果。实际上，我们可以通过提供更少的示例来解决此任务，即仅一个示例似乎就足够了：

*提示：*

```
这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。A：将所有奇数相加（9、15、1）得到25。答案为False。这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。A：
```

*输出：*

```
将所有奇数相加（15、5、13、7、1）得到41。答案为False。
```

请记住，作者声称这是足够大的语言模型才会出现的新兴能力。

#### 零样本COT提示

![Zero-shot COT](https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fzero-cot.79793bee.png&w=1920&q=75)

图片来源：[Kojima等人（2022）(opens in a new tab)](https://arxiv.org/abs/2205.11916)

最近提出的一个新想法是[零样本CoT(opens in a new tab)](https://arxiv.org/abs/2205.11916)（Kojima等人，2022年），它基本上涉及将“让我们逐步思考”添加到原始提示中。让我们尝试一个简单的问题，看看模型的表现如何：

*提示：*

```
我去市场买了10个苹果。我给了邻居2个苹果和修理工2个苹果。然后我去买了5个苹果并吃了1个。我还剩下多少苹果？
```

*输出：*

```
11个苹果
```

答案是不正确的！现在让我们尝试使用特殊提示。

*提示：*

```
我去市场买了10个苹果。我给了邻居2个苹果和修理工2个苹果。然后我去买了5个苹果并吃了1个。我还剩下多少苹果？
让我们逐步思考。
```

*输出：*

```
首先，您从10个苹果开始。
您给了邻居和修理工各2个苹果，所以您还剩下6个苹果。
然后您买了5个苹果，所以现在您有11个苹果。
最后，您吃了1个苹果，所以您还剩下10个苹果。
```

令人印象深刻的是，这个简单的提示在这个任务中非常有效。这在您没有太多示例可用于提示时特别有用。

### 4.自我一致性

也许在提示工程中更高级的技术之一是自我一致性。由[Wang等人（2022）(opens in a new tab)](https://arxiv.org/pdf/2203.11171.pdf)提出，自我一致性旨在“替换链式思维提示中使用的天真贪婪解码方法”。其想法是通过少样本CoT采样多个不同的推理路径，并使用生成结果选择最一致的答案。这有助于提高CoT提示在涉及算术和常识推理的任务中的性能。

让我们尝试以下算术推理示例：

*提示：*

```
当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？
```

*输出：*

```
35
```

输出是错误的！我们如何通过自我一致性来改进这个问题？让我们试试。我们将使用Wang等人2022年的少量样本范例（表17）：

*提示：*

```
Q：林中有15棵树。林业工人今天将在林中种树。完成后，将有21棵树。林业工人今天种了多少棵树？
A：我们从15棵树开始。后来我们有21棵树。差异必须是他们种树的数量。因此，他们必须种了21-15 = 6棵树。答案是6。
Q：停车场有3辆汽车，又来了2辆汽车，停车场有多少辆汽车？
A：停车场已经有3辆汽车。又来了2辆。现在有3 + 2 = 5辆汽车。答案是5。
Q：Leah有32块巧克力，她的姐姐有42块。如果他们吃了35块，他们总共还剩多少块？
A：Leah有32块巧克力，Leah的姐姐有42块。这意味着最初有32 + 42 = 74块巧克力。已经吃了35块。因此，他们总共还剩74-35 = 39块巧克力。答案是39。
Q：Jason有20个棒棒糖。他给Denny一些棒棒糖。现在Jason只有12个棒棒糖。Jason给Denny多少棒棒糖？
A：Jason有20个棒棒糖。因为他现在只有12个，所以他必须把剩下的给Denny。他给Denny的棒棒糖数量必须是20-12 = 8个棒棒糖。答案是8。
Q：Shawn有五个玩具。圣诞节，他从他的父母那里得到了两个玩具。他现在有多少个玩具？
A：他有5个玩具。他从妈妈那里得到了2个，所以在那之后他有5 + 2 = 7个玩具。然后他从爸爸那里得到了2个，所以总共他有7 + 2 = 9个玩具。答案是9。
Q：服务器房间里有9台计算机。从周一到周四，每天都会安装5台计算机。现在服务器房间里有多少台计算机？
A：从周一到周四有4天。每天都添加了5台计算机。这意味着总共添加了4 * 5 =
20台计算机。一开始有9台计算机，所以现在有9 + 20 = 29台计算机。答案是29。
Q：Michael有58个高尔夫球。星期二，他丢失了23个高尔夫球。星期三，他又丢失了2个。星期三结束时他还剩多少个高尔夫球？
A：Michael最初有58个球。星期二他丢失了23个，所以在那之后他有58-23 = 35个球。星期三他又丢失了2个，所以现在他有35-2 = 33个球。答案是33。
Q：Olivia有23美元。她用每个3美元的价格买了五个百吉饼。她还剩多少钱？
A：她用每个3美元的价格买了5个百吉饼。这意味着她花了5
Q：当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？
A：

```

*输出1：*

```
当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70-3 = 67岁。答案是67。
```

*输出2：*

```
当叙述者6岁时，他的妹妹是他年龄的一半，也就是3岁。现在叙述者70岁了，他的妹妹应该是70-3 = 67岁。答案是67。
```

*输出3：*

```
当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70/2 = 35岁。答案是35。
```

计算最终答案涉及几个步骤（详见论文），但为了简单起见，我们可以看到已经出现了大多数答案，因此这基本上将成为最终答案。

### 5.生成知识提示

![GENKNOW](https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fgen-knowledge.055b8d37.png&w=1920&q=75)

图片来源：[Liu等人2022(opens in a new tab)](https://arxiv.org/pdf/2110.08387.pdf)

LLM继续得到改进，其中一种流行的技术是能够融合知识或信息，以帮助模型做出更准确的预测。

使用类似的思路，模型是否也可以在做出预测之前用于生成知识呢？这就是[Liu等人2022(opens in a new tab)](https://arxiv.org/pdf/2110.08387.pdf)的论文所尝试的——生成知识以作为提示的一部分。特别是，这对于常识推理等任务有多大帮助？

让我们尝试一个简单的提示：

*提示：*

```
高尔夫球的一部分是试图获得比其他人更高的得分。是或否？
```

*输出：*

```
是。
```

这种错误揭示了LLM在执行需要更多关于世界的知识的任务时的局限性。我们如何通过生成知识来改进呢？

首先，我们生成一些“知识”：

*提示：*

```
输入：希腊比墨西哥大。
知识：希腊的面积约为131,957平方公里，而墨西哥的面积约为1,964,375平方公里，使墨西哥比希腊大了1,389%。
输入：眼镜总是会起雾。
知识：当你的汗水、呼吸和周围的湿度中的水蒸气落在冷的表面上，冷却并变成微小的液滴时，会在眼镜镜片上产生冷凝。你看到的是一层薄膜。你的镜片相对于你的呼吸会比较凉，尤其是当外面的空气很冷时。
输入：鱼有思考能力。
知识：鱼比它们看起来更聪明。在许多领域，如记忆力，它们的认知能力与或超过非人类灵长类动物等“更高级”的脊椎动物。鱼的长期记忆帮助它们跟踪复杂的社交关系。
输入：一个人一生中吸烟很多香烟的常见影响是患肺癌的几率高于正常水平。
知识：那些一生中平均每天吸烟不到一支香烟的人，患肺癌的风险是从不吸烟者的9倍。在每天吸烟1到10支香烟之间的人群中，死于肺癌的风险几乎是从不吸烟者的12倍。
输入：一块石头和一颗卵石大小相同。
知识：卵石是一种根据Udden-Wentworth沉积学尺度的颗粒大小为4到64毫米的岩屑。卵石通常被认为比颗粒（直径2到4毫米）大，比卵石（直径64到256毫米）小。
输入：高尔夫球的一部分是试图获得比其他人更高的得分。
知识：
```

*知识1：*

```
高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。
```

*知识2：*

```
高尔夫球是一项精密的球杆运动，竞争选手（或高尔夫球手）使用许多类型的球杆，用最少的杆数将球打入球场上一系列洞中。目标是以最低的分数完成比赛，该分数是通过将每个洞上所用的杆数相加计算出来的。得分最低的选手赢得比赛。
```

我们使用[Liu等人2022(opens in a new tab)](https://arxiv.org/pdf/2110.08387.pdf)的论文中提供的提示。

下一步是将知识整合并得出预测。我将问题重新格式化为QA格式，以指导答案格式。

*提示：*

```
问题：高尔夫球的一部分是试图获得比其他人更高的得分。是或否？
知识：高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。
解释和答案： 
```

*答案1（置信度非常高）：*

```
不是，高尔夫球的目标不是获得比其他人更高的得分。相反，目标是以最少的杆数打完一组洞。总杆数用于确定比赛的获胜者，而不是总得分。
```

```
问题：高尔夫球的一部分是试图获得比其他人更高的得分。是或否？
知识：高尔夫球是一项精密的球杆运动，竞争选手（或高尔夫球手）使用许多类型的球杆，用最少的杆数将球打入球场上一系列洞中。目标是以最低的分数完成比赛，该分数是通过将每个洞上所用的杆数相加计算出来的。得分最低的选手赢得比赛。
解释和答案：
```

*答案2（置信度要低得多）：*

```
是的，高尔夫球的一部分是试图获得比其他人更高的得分。每个选手都试图以最少的杆数打完一组洞。总杆数用于确定比赛的获胜者，而不是总得分。得分最低的选手赢得比赛。
```

这个例子发生了一些非常有趣的事情。在第一个答案中，模型非常自信，但在第二个答案中不太自信。我简化了过程以进行演示，但在得出最终答案时还有一些细节需要考虑。请查看论文以了解更多。

## 二、提示原则

### 1.清晰明确的指令

#### 1.1 使用分隔符

> - 你可以使用任何明显的标点符号将特定的文本部分与提示的其余部分分开。这可以是任何可以使模型明确知道这是一个单独部分的标记。
> - 使用分隔符是一种可以避免提示注入的有用技术。

#### 1.2 结构化的输出

> * 要求生成一个结构化的输出，这可以使模型的输出更可读，或更容易被我们解析。
> * Json、表格等

#### 1.3 **要求模型检查是否满足条件**

如果任务做出的假设不一定满足，我们可以告诉模型先检查这些假设，如果不满足，指示并停止执行。你还可以考虑潜在的边缘情况以及模型应该如何处理它们，以避免意外的错误或结果。

#### 1.4 提供少量示例

即在要求模型执行实际任务之前，提供给它少量成功执行任务的示例。

### 2.给模型时间去思考

如果模型匆忙地得出了错误的结论，您应该尝试重新构思查询，请求模型在提供最终答案之前进行一系列相关的推理。换句话说，如果您给模型一个在短时间或用少量文字无法完成的任务，它可能会猜测错误。

#### 2.1 **指定完成任务所需的步骤**

将复杂任务拆分成多个多个步骤

#### **2.2 指导模型在下结论之前找出一个自己的解法**

## 二、如何写好提示词

提示词的基本原则

提示词基本公式：时间、地点、人物、背景、目标、任务
